{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 Observability & SLOs\n",
    "\n",
    "This notebook covers:\n",
    "- OpenTelemetry instrumentation\n",
    "- Traces, metrics, and logs\n",
    "- SLI/SLO definitions\n",
    "- Error budgets\n",
    "- Dashboards and alerting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters cell for Papermill\n",
    "run_mode = \"interactive\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenTelemetry Overview\n",
    "\n",
    "OpenTelemetry provides a unified observability framework for traces, metrics, and logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otel_components = {\n",
    "    \"SDK\": \"Instrument your application\",\n",
    "    \"API\": \"Language-agnostic interface\",\n",
    "    \"Collector\": \"Receive, process, and export telemetry\",\n",
    "    \"Exporters\": \"Send data to backends (Jaeger, Prometheus, etc.)\",\n",
    "    \"Auto-instrumentation\": \"Zero-code instrumentation for popular frameworks\",\n",
    "}\n",
    "\n",
    "print(\"OpenTelemetry Components:\")\n",
    "for component, desc in otel_components.items():\n",
    "    print(f\"  • {component}: {desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Three Pillars of Observability\n",
    "\n",
    "### 1. Traces\n",
    "Track requests across service boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_example = \"\"\"\n",
    "Trace Example:\n",
    "\n",
    "TraceID: abc123...\n",
    "├─ Span: API Gateway (100ms)\n",
    "│  ├─ Span: Auth Service (20ms)\n",
    "│  └─ Span: User Service (70ms)\n",
    "│     ├─ Span: Database Query (50ms)\n",
    "│     └─ Span: Cache Lookup (5ms)\n",
    "\n",
    "Benefits:\n",
    "- Identify bottlenecks\n",
    "- Debug latency issues\n",
    "- Understand service dependencies\n",
    "\"\"\"\n",
    "\n",
    "print(trace_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Metrics\n",
    "Quantitative measurements over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_types = {\n",
    "    \"Counter\": \"Monotonically increasing (e.g., request count)\",\n",
    "    \"Gauge\": \"Point-in-time value (e.g., CPU usage)\",\n",
    "    \"Histogram\": \"Distribution of values (e.g., request duration)\",\n",
    "    \"Summary\": \"Aggregated statistics (e.g., percentiles)\",\n",
    "}\n",
    "\n",
    "print(\"Metric Types:\")\n",
    "for mtype, desc in metric_types.items():\n",
    "    print(f\"  • {mtype}: {desc}\")\n",
    "\n",
    "print(\"\\nCommon Metrics:\")\n",
    "print(\"  - Request rate (requests/sec)\")\n",
    "print(\"  - Error rate (errors/sec or %)\")\n",
    "print(\"  - Latency (p50, p95, p99)\")\n",
    "print(\"  - Saturation (CPU, memory, disk)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Logs\n",
    "Structured event records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "structured_log = {\n",
    "    \"timestamp\": \"2024-01-01T12:00:00Z\",\n",
    "    \"level\": \"ERROR\",\n",
    "    \"message\": \"Database connection failed\",\n",
    "    \"service\": \"user-service\",\n",
    "    \"trace_id\": \"abc123\",\n",
    "    \"span_id\": \"def456\",\n",
    "    \"error\": {\"type\": \"ConnectionError\", \"message\": \"Connection timeout after 5s\"},\n",
    "    \"context\": {\"user_id\": \"12345\", \"endpoint\": \"/api/users\"},\n",
    "}\n",
    "\n",
    "print(\"Structured Log Example:\")\n",
    "print(json.dumps(structured_log, indent=2))\n",
    "\n",
    "print(\"\\nBest Practices:\")\n",
    "print(\"  • Use structured logging (JSON)\")\n",
    "print(\"  • Include trace/span IDs for correlation\")\n",
    "print(\"  • Add contextual information\")\n",
    "print(\"  • Avoid PII in logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLI/SLO/SLA Framework\n",
    "\n",
    "Define and track service reliability targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sli_slo_example = {\n",
    "    \"service\": \"user-api\",\n",
    "    \"slis\": [\n",
    "        {\n",
    "            \"name\": \"Availability\",\n",
    "            \"description\": \"Percentage of successful requests\",\n",
    "            \"measurement\": \"(successful_requests / total_requests) * 100\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Latency\",\n",
    "            \"description\": \"Request duration\",\n",
    "            \"measurement\": \"p95 latency in milliseconds\",\n",
    "        },\n",
    "    ],\n",
    "    \"slos\": [\n",
    "        {\"sli\": \"Availability\", \"target\": \"99.9%\", \"window\": \"30 days\"},\n",
    "        {\n",
    "            \"sli\": \"Latency\",\n",
    "            \"target\": \"< 200ms\",\n",
    "            \"percentile\": \"p95\",\n",
    "            \"window\": \"30 days\",\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "print(\"SLI/SLO Example:\")\n",
    "print(json.dumps(sli_slo_example, indent=2))\n",
    "\n",
    "print(\"\\nDefinitions:\")\n",
    "print(\"  • SLI (Service Level Indicator): A quantitative measure\")\n",
    "print(\"  • SLO (Service Level Objective): Target range for SLI\")\n",
    "print(\"  • SLA (Service Level Agreement): Contractual commitment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Budgets\n",
    "\n",
    "Balance reliability and feature velocity using error budgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error budget calculation\n",
    "slo_target = 99.9  # 99.9% availability\n",
    "days_in_month = 30\n",
    "minutes_in_month = days_in_month * 24 * 60\n",
    "\n",
    "# Allowed downtime\n",
    "error_budget_percent = 100 - slo_target\n",
    "error_budget_minutes = minutes_in_month * (error_budget_percent / 100)\n",
    "\n",
    "print(f\"SLO Target: {slo_target}%\")\n",
    "print(f\"Error Budget: {error_budget_percent}%\")\n",
    "print(f\"Allowed Downtime: {error_budget_minutes:.2f} minutes/month\")\n",
    "print(f\"                  {error_budget_minutes / 60:.2f} hours/month\")\n",
    "\n",
    "print(\"\\nError Budget Policy:\")\n",
    "print(\"  • 100% budget remaining: Full speed ahead\")\n",
    "print(\"  • 50% budget remaining: Review change velocity\")\n",
    "print(\"  • 0% budget remaining: Feature freeze, focus on reliability\")\n",
    "print(\"  • Negative budget: Incident response, postmortem required\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dashboards & Alerting\n",
    "\n",
    "Visualize and alert on key metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard_structure = \"\"\"\n",
    "Golden Signals Dashboard:\n",
    "\n",
    "1. Latency\n",
    "   - p50, p95, p99 request duration\n",
    "   - Breakdown by endpoint\n",
    "\n",
    "2. Traffic\n",
    "   - Requests per second\n",
    "   - Breakdown by method/endpoint\n",
    "\n",
    "3. Errors\n",
    "   - Error rate (%)\n",
    "   - Error count by type\n",
    "\n",
    "4. Saturation\n",
    "   - CPU utilization\n",
    "   - Memory usage\n",
    "   - Queue depth\n",
    "\"\"\"\n",
    "\n",
    "print(dashboard_structure)\n",
    "\n",
    "alerting_rules = [\n",
    "    \"High error rate: > 1% for 5 minutes\",\n",
    "    \"High latency: p95 > 500ms for 5 minutes\",\n",
    "    \"SLO burn rate: Burning error budget 10x faster than acceptable\",\n",
    "    \"Service unavailable: 0 healthy instances\",\n",
    "]\n",
    "\n",
    "print(\"\\nAlerting Rules:\")\n",
    "for rule in alerting_rules:\n",
    "    print(f\"  • {rule}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Observability & SLOs notebook complete! (mode: {run_mode})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
